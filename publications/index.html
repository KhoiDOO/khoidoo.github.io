<!doctype html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> publications | Khoi Hoang Do </title> <meta name="author" content="Khoi Hoang Do"> <meta name="description" content="publications by categories in reversed chronological order. generated by jekyll-scholar."> <meta name="keywords" content="Generative AI, 3D Content Generation"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>⚛️</text></svg>" > <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://khoidoo.github.io/publications/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Khoi</span> Hoang Do </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description">publications by categories in reversed chronological order. generated by jekyll-scholar.</p> </header> <article> <script src="/assets/js/bibsearch.js?1bc438ca9037884cc579601c09afd847" type="module"></script> <p><input type="text" id="bibsearch" spellcheck="false" autocomplete="off" class="search bibsearch-form-input" placeholder="Type to filter"/></p> <div class="publications"> <h2 class="bibliography">2024</h2> <ol class="bibliography"><li><div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="do2024revisitinglarslargebatch" class="col-sm-8"> <div class="title">Revisiting LARS for Large Batch Training Generalization of Neural Networks</div> <div class="author"> <em>Khoi Do</em>,&nbsp;Duong Nguyen,&nbsp;Hoa Nguyen,&nbsp;Long Tran-Thanh,&nbsp;Nguyen-Hoang Tran, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Quoc-Viet Pham' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://github.com/KhoiDOO/tvlars" class="btn btn-sm z-depth-0" role="button">Code</a> </div> <div class="abstract hidden"> <p>This paper explores Large Batch Training techniques using layer-wise adaptive scaling ratio (LARS) across diverse settings, uncovering insights. LARS algorithms with warm-up tend to be trapped in sharp minimizers early on due to redundant ratio scaling. Additionally, a fixed steep decline in the latter phase restricts deep neural networks from effectively navigating early-phase sharp minimizers. Building on these findings, we propose Time Varying LARS (TVLARS), a novel algorithm that replaces warm-up with a configurable sigmoid-like function for robust training in the initial phase. TVLARS promotes gradient exploration early on, surpassing sharp optimizers and gradually transitioning to LARS for robustness in later phases. Extensive experiments demonstrate that TVLARS consistently outperforms LARS and LAMB in most cases, with up to 2% improvement in classification scenarios. Notably, in all self-supervised learning cases, TVLARS dominates LARS and LAMB with performance improvements of up to 10%.</p> </div> </div> </div> </li> <li><div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="nguyen2024layerwisepersonalizedfederatedlearning" class="col-sm-8"> <div class="title">Towards Layer-Wise Personalized Federated Learning: Adaptive Layer Disentanglement via Conflicting Gradients</div> <div class="author"> Minh Duong Nguyen,&nbsp;Khanh Le,&nbsp;<em>Khoi Do</em>,&nbsp;Nguyen H. Tran,&nbsp;Duc Nguyen, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Chien Trinh, Zhaohui Yang' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://github.com/khanhkhanhlele/FedLAG" class="btn btn-sm z-depth-0" role="button">Code</a> </div> <div class="abstract hidden"> <p>In personalized Federated Learning (pFL), high data heterogeneity can cause significant gradient divergence across devices, adversely affecting the learning process. This divergence, especially when gradients from different users form an obtuse angle during aggregation, can negate progress, leading to severe weight and gradient update degradation. To address this issue, we introduce a new approach to pFL design, namely Federated Learning with Layer-wise Aggregation via Gradient Analysis (FedLAG), utilizing the concept of gradient conflict at the layer level. Specifically, when layer-wise gradients of different clients form acute angles, those gradients align in the same direction, enabling updates across different clients toward identifying client-invariant features. Conversely, when layer-wise gradient pairs make create obtuse angles, the layers tend to focus on client-specific tasks. In hindsights, FedLAG assigns layers for personalization based on the extent of layer-wise gradient conflicts. Specifically, layers with gradient conflicts are excluded from the global aggregation process. The theoretical evaluation demonstrates that when integrated into other pFL baselines, FedLAG enhances pFL performance by a certain margin. Therefore, our proposed method achieves superior convergence behavior compared with other baselines. Extensive experiments show that our FedLAG outperforms several state-of-the-art methods and can be easily incorporated with many existing methods to further enhance performance.</p> </div> </div> </div> </li> <li><div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="10.1007/978-3-031-44630-6_43" class="col-sm-8"> <div class="title">Block-Based Texture Features for Chromoendoscopy Classification</div> <div class="author"> Viet Dung Nguyen,&nbsp;Hoang Nam Trinh,&nbsp;and&nbsp;Hoang Khoi Do </div> <div class="periodical"> <em>In 9th International Conference on the Development of Biomedical Engineering in Vietnam</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>Globally, there has been an upsurge in concern about stomach cancer in recent years. One of the key factors contributing to gastrointestinal (GI) tract abnormalities, such as ulcers and inflammation, is an improper diet. Additionally, these anomalies might aid in the growth of stomach cancer. Compared to biopsy, endoscopy is a less invasive way to screen gastric cancer and other GI tract abnormalities. In chromoendoscopy, one of the advancements to endoscopy, abnormal regions are made more visible visually by spraying colors over the mucosal surface. However, identifying abnormal regions in the frames taken during a chromoendoscopic session is still challenging. Basic visual cues like textures help to identify objects. They are helpful for inspecting abnormal spots in endoscopic frames as well. Several methods for representing texture and classifying endoscopic images have been developed. In this study, we proposed block-based texture features, especially Block Difference of Inverse Probabilities (BIDP) and Block Variation of Local Correlation Coefficients (BVLC), to represent the chromoendoscopic texture. The extracted features are then used to classify the chromoendoscopic image into normal and abnormal. On the dataset obtained using an Olympus CV-180 endoscope at the Portuguese Institute of Oncology (IPO) Hospital in Porto, Portugal, the proposed scheme has a classification accuracy of 88.9% and an area under the curve (AUC) value of 0.95, according to experimental results. It is proved that combining the BDIP and BLVC texture descriptors exhibits an excellent discrimination performance on the chromoendoscopic images. Though the proposed method is limited to chromoendoscopic images, it has the potential to be generalized by using images obtained from various imaging modalities under a variety of unhealthy conditions.</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"><li><div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="10207979" class="col-sm-8"> <div class="title">Semantic Communication for Partial Observation Multi-agent Reinforcement Learning</div> <div class="author"> Hoang Khoi Do,&nbsp;Thi Quynh Dinh,&nbsp;Minh Duong Nguyen,&nbsp;and&nbsp;Tien Hoa Nguyen </div> <div class="periodical"> <em>In 2023 IEEE Statistical Signal Processing Workshop (SSP)</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1109/SSP53291.2023.10207979" class="btn btn-sm z-depth-0" role="button">DOI</a> <a href="https://github.com/ScaleMind-C9308A/some" class="btn btn-sm z-depth-0" role="button">Code</a> </div> </div> </div> </li> <li><div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="10.1007/978-981-99-4725-6_31" class="col-sm-8"> <div class="title">Personal Federated Learning via Momentum Target with Self-Improvement</div> <div class="author"> T-Binh Nguyen,&nbsp;H-Khoi Do,&nbsp;M-Duong Nguyen,&nbsp;and&nbsp;T-Hoa Nguyen </div> <div class="periodical"> <em>In Intelligent Systems and Networks</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>Federated learning (FL) is a new artificial intelligence concept that enables Internet-of-Things (IoT) devices to learn a collaborative model without sending the raw data to centralized nodes for processing. Despite numerous advantages, Federated Learning faces huge challenges from model overfitting due to the lack of data and statistical diversity among clients. To address these challenges, we propose a novel personalized federated learning method via momentum adaptation, the so-called pFLTI. Specifically, pFLTI generates the target model by adapting from the temporal ensemble of the meta-learner, i.e., the momentum network. This momentum network and its task-specific adaptations enjoy a favorable generalization performance, enabling self-improving of the meta-learner through knowlodels to find the across task relationsedge distillation. Moreover, we found that perturbing parameters of the meta-learner, e.g., dropout, further stabilize this self-improving process by preventing fast convergence of the distillation loss during meta-training. Our experimental results demonstrate that our algorithm is awesome.</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"><li><div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="s22197530" class="col-sm-8"> <div class="title">Skin Lesion Classification on Imbalanced Data Using Deep Learning with Soft Attention</div> <div class="author"> Viet Dung Nguyen,&nbsp;Ngoc Dung Bui,&nbsp;and&nbsp;Hoang Khoi Do </div> <div class="periodical"> <em>Sensors</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.3390/s22197530" class="btn btn-sm z-depth-0" role="button">DOI</a> <a href="https://github.com/KhoiDOO/SLC-ID-SA" class="btn btn-sm z-depth-0" role="button">Code</a> </div> <div class="abstract hidden"> <p>Today, the rapid development of industrial zones leads to an increased incidence of skin diseases because of polluted air. According to a report by the American Cancer Society, it is estimated that in 2022 there will be about 100,000 people suffering from skin cancer and more than 7600 of these people will not survive. In the context that doctors at provincial hospitals and health facilities are overloaded, doctors at lower levels lack experience, and having a tool to support doctors in the process of diagnosing skin diseases quickly and accurately is essential. Along with the strong development of artificial intelligence technologies, many solutions to support the diagnosis of skin diseases have been researched and developed. In this paper, a combination of one Deep Learning model (DenseNet, InceptionNet, ResNet, etc) with Soft-Attention, which unsupervisedly extract a heat map of main skin lesions. Furthermore, personal information including age and gender are also used. It is worth noting that a new loss function that takes into account the data imbalance is also proposed. Experimental results on data set HAM10000 show that using InceptionResNetV2 with Soft-Attention and the new loss function gives 90 percent accuracy, mean of precision, F1-score, recall, and AUC of 0.81, 0.81, 0.82, and 0.99, respectively. Besides, using MobileNetV3Large combined with Soft-Attention and the new loss function, even though the number of parameters is 11 times less and the number of hidden layers is 4 times less, it achieves an accuracy of 0.86 and 30 times faster diagnosis than InceptionResNetV2.</p> </div> </div> </div> </li> <li><div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="10013868" class="col-sm-8"> <div class="title">Endoscopic Image Classification using Block-based Color Feature Descriptors</div> <div class="author"> Viet Dung Nguyen,&nbsp;Minh Phuong Luong,&nbsp;and&nbsp;Hoang Khoi Do </div> <div class="periodical"> <em>In 2022 RIVF International Conference on Computing and Communication Technologies (RIVF)</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1109/RIVF55975.2022.10013868" class="btn btn-sm z-depth-0" role="button">DOI</a> <a href="https://github.com/ScaleMind-C9308A/CE-AB-CLS" class="btn btn-sm z-depth-0" role="button">Code</a> </div> </div> </div> </li></ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> &copy; Copyright 2024 Khoi Hoang Do. Powered by <a href="https://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>. Last updated: October 29, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> </body> </html>